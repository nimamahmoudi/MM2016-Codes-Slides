
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      --><title>Feature Based Panoramic Image Stitching</title><meta name="generator" content="MATLAB 9.1"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2016-10-31"><meta name="DC.source" content="FeatureBasedPanoramicImageStitchingExample.m"><style type="text/css">
html,body,div,span,applet,object,iframe,h1,h2,h3,h4,h5,h6,p,blockquote,pre,a,abbr,acronym,address,big,cite,code,del,dfn,em,font,img,ins,kbd,q,s,samp,small,strike,strong,sub,sup,tt,var,b,u,i,center,dl,dt,dd,ol,ul,li,fieldset,form,label,legend,table,caption,tbody,tfoot,thead,tr,th,td{margin:0;padding:0;border:0;outline:0;font-size:100%;vertical-align:baseline;background:transparent}body{line-height:1}ol,ul{list-style:none}blockquote,q{quotes:none}blockquote:before,blockquote:after,q:before,q:after{content:'';content:none}:focus{outine:0}ins{text-decoration:none}del{text-decoration:line-through}table{border-collapse:collapse;border-spacing:0}

html { min-height:100%; margin-bottom:1px; }
html body { height:100%; margin:0px; font-family:Arial, Helvetica, sans-serif; font-size:10px; color:#000; line-height:140%; background:#fff none; overflow-y:scroll; }
html body td { vertical-align:top; text-align:left; }

h1 { padding:0px; margin:0px 0px 25px; font-family:Arial, Helvetica, sans-serif; font-size:1.5em; color:#d55000; line-height:100%; font-weight:normal; }
h2 { padding:0px; margin:0px 0px 8px; font-family:Arial, Helvetica, sans-serif; font-size:1.2em; color:#000; font-weight:bold; line-height:140%; border-bottom:1px solid #d6d4d4; display:block; }
h3 { padding:0px; margin:0px 0px 5px; font-family:Arial, Helvetica, sans-serif; font-size:1.1em; color:#000; font-weight:bold; line-height:140%; }

a { color:#005fce; text-decoration:none; }
a:hover { color:#005fce; text-decoration:underline; }
a:visited { color:#004aa0; text-decoration:none; }

p { padding:0px; margin:0px 0px 20px; }
img { padding:0px; margin:0px 0px 20px; border:none; }
p img, pre img, tt img, li img, h1 img, h2 img { margin-bottom:0px; } 

ul { padding:0px; margin:0px 0px 20px 23px; list-style:square; }
ul li { padding:0px; margin:0px 0px 7px 0px; }
ul li ul { padding:5px 0px 0px; margin:0px 0px 7px 23px; }
ul li ol li { list-style:decimal; }
ol { padding:0px; margin:0px 0px 20px 0px; list-style:decimal; }
ol li { padding:0px; margin:0px 0px 7px 23px; list-style-type:decimal; }
ol li ol { padding:5px 0px 0px; margin:0px 0px 7px 0px; }
ol li ol li { list-style-type:lower-alpha; }
ol li ul { padding-top:7px; }
ol li ul li { list-style:square; }

.content { font-size:1.2em; line-height:140%; padding: 20px; }

pre, code { font-size:12px; }
tt { font-size: 1.2em; }
pre { margin:0px 0px 20px; }
pre.codeinput { padding:10px; border:1px solid #d3d3d3; background:#f7f7f7; }
pre.codeoutput { padding:10px 11px; margin:0px 0px 20px; color:#4c4c4c; }
pre.error { color:red; }

@media print { pre.codeinput, pre.codeoutput { word-wrap:break-word; width:100%; } }

span.keyword { color:#0000FF }
span.comment { color:#228B22 }
span.string { color:#A020F0 }
span.untermstring { color:#B20000 }
span.syscmd { color:#B28C00 }

.footer { width:auto; padding:10px 0px; margin:25px 0px 0px; border-top:1px dotted #878787; font-size:0.8em; line-height:140%; font-style:italic; color:#878787; text-align:left; float:none; }
.footer p { margin:0px; }
.footer a { color:#878787; }
.footer a:hover { color:#878787; text-decoration:underline; }
.footer a:visited { color:#878787; }

table th { padding:7px 5px; text-align:left; vertical-align:middle; border: 1px solid #d6d4d4; font-weight:bold; }
table td { padding:7px 5px; text-align:left; vertical-align:top; border:1px solid #d6d4d4; }





  </style></head><body><div class="content"><h1>Feature Based Panoramic Image Stitching</h1><!--introduction--><p>This example shows how to automatically create a panorama using feature based image registration techniques.</p><!--/introduction--><h2>Contents</h2><div><ul><li><a href="#1">Overview</a></li><li><a href="#2">Step 1 - Load Images</a></li><li><a href="#3">Step 2 - Register Image Pairs</a></li><li><a href="#7">Step 3 - Initialize the Panorama</a></li><li><a href="#8">Step 4 - Create the Panorama</a></li><li><a href="#9">Conclusion</a></li><li><a href="#10">References</a></li></ul></div><h2 id="1">Overview</h2><p>Feature detection and matching are powerful techniques used in many computer vision applications such as image registration, tracking, and object detection. In this example, feature based techniques are used to automatically stitch together a set of images. The procedure for image stitching is an extension of feature based image registration. Instead of registering a single pair of images, multiple image pairs are successively registered relative to each other to form a panorama.</p><h2 id="2">Step 1 - Load Images</h2><p>The image set used in this example contains pictures of a building. These were taken with an uncalibrated smart phone camera by sweeping the camera from left to right along the horizon, capturing all parts of the building.</p><p>As seen below, the images are relatively unaffected by any lens distortion so camera calibration was not required. However, if lens distortion is present, the camera should be calibrated and the images undistorted prior to creating the panorama. You can use the <tt><a href="matlab:doc('cameraCalibrator');">cameraCalibrator</a></tt> App to calibrate a camera if needed.</p><pre class="codeinput"><span class="comment">% Load images.</span>
buildingDir = fullfile(toolboxdir(<span class="string">'vision'</span>), <span class="string">'visiondata'</span>, <span class="string">'building'</span>);
buildingScene = imageDatastore(buildingDir);

<span class="comment">% Display images to be stitched</span>
montage(buildingScene.Files)
</pre><img vspace="5" hspace="5" src="FeatureBasedPanoramicImageStitchingExample_01.png" style="width:661px;height:666px;" alt=""> <h2 id="3">Step 2 - Register Image Pairs</h2><p>To create the panorama, start by registering successive image pairs using the following procedure:</p><div><ol><li>Detect and match features between <img src="FeatureBasedPanoramicImageStitchingExample_eq15829090651170517336.png" alt="$I(n)$" style="width:27px;height:16px;"> and <img src="FeatureBasedPanoramicImageStitchingExample_eq02270291248613918900.png" alt="$I(n-1)$" style="width:52px;height:16px;">.</li><li>Estimate the geometric transformation, <img src="FeatureBasedPanoramicImageStitchingExample_eq13911208833169113548.png" alt="$T(n)$" style="width:30px;height:16px;">, that maps <img src="FeatureBasedPanoramicImageStitchingExample_eq15829090651170517336.png" alt="$I(n)$" style="width:27px;height:16px;"> to <img src="FeatureBasedPanoramicImageStitchingExample_eq02270291248613918900.png" alt="$I(n-1)$" style="width:52px;height:16px;">.</li><li>Compute the transformation that maps <img src="FeatureBasedPanoramicImageStitchingExample_eq15829090651170517336.png" alt="$I(n)$" style="width:27px;height:16px;"> into the panorama image as <img src="FeatureBasedPanoramicImageStitchingExample_eq09274134294194457001.png" alt="$T(1) * ... * T(n-1) * T(n)$" style="width:170px;height:16px;">.</li></ol></div><pre class="codeinput"><span class="comment">% Read the first image from the image set.</span>
I = readimage(buildingScene, 1);

<span class="comment">% Initialize features for I(1)</span>
grayImage = rgb2gray(I);
points = detectSURFFeatures(grayImage);
[features, points] = extractFeatures(grayImage, points);

<span class="comment">% Initialize all the transforms to the identity matrix. Note that the</span>
<span class="comment">% projective transform is used here because the building images are fairly</span>
<span class="comment">% close to the camera. Had the scene been captured from a further distance,</span>
<span class="comment">% an affine transform would suffice.</span>
numImages = numel(buildingScene.Files);
tforms(numImages) = projective2d(eye(3));

<span class="comment">% Iterate over remaining image pairs</span>
<span class="keyword">for</span> n = 2:numImages

    <span class="comment">% Store points and features for I(n-1).</span>
    pointsPrevious = points;
    featuresPrevious = features;

    <span class="comment">% Read I(n).</span>
    I = readimage(buildingScene, n);

    <span class="comment">% Detect and extract SURF features for I(n).</span>
    grayImage = rgb2gray(I);
    points = detectSURFFeatures(grayImage);
    [features, points] = extractFeatures(grayImage, points);

    <span class="comment">% Find correspondences between I(n) and I(n-1).</span>
    indexPairs = matchFeatures(features, featuresPrevious, <span class="string">'Unique'</span>, true);

    matchedPoints = points(indexPairs(:,1), :);
    matchedPointsPrev = pointsPrevious(indexPairs(:,2), :);

    <span class="comment">% Estimate the transformation between I(n) and I(n-1).</span>
    tforms(n) = estimateGeometricTransform(matchedPoints, matchedPointsPrev,<span class="keyword">...</span>
        <span class="string">'projective'</span>, <span class="string">'Confidence'</span>, 99.9, <span class="string">'MaxNumTrials'</span>, 2000);

    <span class="comment">% Compute T(1) * ... * T(n-1) * T(n)</span>
    tforms(n).T = tforms(n-1).T * tforms(n).T;
<span class="keyword">end</span>
</pre><p>At this point, all the transformations in <tt>tforms</tt> are relative to the first image. This was a convenient way to code the image registration procedure because it allowed sequential processing of all the images. However, using the first image as the start of the panorama does not produce the most aesthetically pleasing panorama because it tends to distort most of the images that form the panorama. A nicer panorama can be created by modifying the transformations such that the center of the scene is the least distorted. This is accomplished by inverting the transform for the center image and applying that transform to all the others.</p><p>Start by using the <tt>projective2d</tt> <tt>outputLimits</tt> method to find the output limits for each transform. The output limits are then used to automatically find the image that is roughly in the center of the scene.</p><pre class="codeinput">imageSize = size(I);  <span class="comment">% all the images are the same size</span>

<span class="comment">% Compute the output limits  for each transform</span>
<span class="keyword">for</span> i = 1:numel(tforms)
    [xlim(i,:), ylim(i,:)] = outputLimits(tforms(i), [1 imageSize(2)], [1 imageSize(1)]);
<span class="keyword">end</span>
</pre><p>Next, compute the average X limits for each transforms and find the image that is in the center. Only the X limits are used here because the scene is known to be horizontal. If another set of images are used, both the X and Y limits may need to be used to find the center image.</p><pre class="codeinput">avgXLim = mean(xlim, 2);

[~, idx] = sort(avgXLim);

centerIdx = floor((numel(tforms)+1)/2);

centerImageIdx = idx(centerIdx);
</pre><p>Finally, apply the center image's inverse transform to all the others.</p><pre class="codeinput">Tinv = invert(tforms(centerImageIdx));

<span class="keyword">for</span> i = 1:numel(tforms)
    tforms(i).T = Tinv.T * tforms(i).T;
<span class="keyword">end</span>
</pre><h2 id="7">Step 3 - Initialize the Panorama</h2><p>Now, create an initial, empty, panorama into which all the images are mapped.</p><p>Use the <tt>outputLimits</tt> method to compute the minimum and maximum output limits over all transformations. These values are used to automatically compute the size of the panorama.</p><pre class="codeinput"><span class="keyword">for</span> i = 1:numel(tforms)
    [xlim(i,:), ylim(i,:)] = outputLimits(tforms(i), [1 imageSize(2)], [1 imageSize(1)]);
<span class="keyword">end</span>

<span class="comment">% Find the minimum and maximum output limits</span>
xMin = min([1; xlim(:)]);
xMax = max([imageSize(2); xlim(:)]);

yMin = min([1; ylim(:)]);
yMax = max([imageSize(1); ylim(:)]);

<span class="comment">% Width and height of panorama.</span>
width  = round(xMax - xMin);
height = round(yMax - yMin);

<span class="comment">% Initialize the "empty" panorama.</span>
panorama = zeros([height width 3], <span class="string">'like'</span>, I);
</pre><h2 id="8">Step 4 - Create the Panorama</h2><p>Use <tt>imwarp</tt> to map images into the panorama and use <tt>vision.AlphaBlender</tt> to overlay the images together.</p><pre class="codeinput">blender = vision.AlphaBlender(<span class="string">'Operation'</span>, <span class="string">'Binary mask'</span>, <span class="keyword">...</span>
    <span class="string">'MaskSource'</span>, <span class="string">'Input port'</span>);

<span class="comment">% Create a 2-D spatial reference object defining the size of the panorama.</span>
xLimits = [xMin xMax];
yLimits = [yMin yMax];
panoramaView = imref2d([height width], xLimits, yLimits);

<span class="comment">% Create the panorama.</span>
<span class="keyword">for</span> i = 1:numImages

    I = readimage(buildingScene, i);

    <span class="comment">% Transform I into the panorama.</span>
    warpedImage = imwarp(I, tforms(i), <span class="string">'OutputView'</span>, panoramaView);

    <span class="comment">% Generate a binary mask.</span>
    mask = imwarp(true(size(I,1),size(I,2)), tforms(i), <span class="string">'OutputView'</span>, panoramaView);

    <span class="comment">% Overlay the warpedImage onto the panorama.</span>
    panorama = step(blender, panorama, warpedImage, mask);
<span class="keyword">end</span>

figure
imshow(panorama)
</pre><img vspace="5" hspace="5" src="FeatureBasedPanoramicImageStitchingExample_02.png" style="width:1275px;height:496px;" alt=""> <h2 id="9">Conclusion</h2><p>This example showed you how to automatically create a panorama using feature based image registration techniques. Additional techniques can be incorporated into the example to improve the blending and alignment of the panorama images[1].</p><h2 id="10">References</h2><p>[1] Matthew Brown and David G. Lowe. 2007. Automatic Panoramic Image     Stitching using Invariant Features. Int. J. Comput. Vision 74, 1     (August 2007), 59-73.</p><p class="footer">Copyright 2014 The MathWorks, Inc.<br><a href="http://www.mathworks.com/products/matlab/">Published with MATLAB&reg; R2016b</a><br></p></div><!--
##### SOURCE BEGIN #####
%% Feature Based Panoramic Image Stitching
% This example shows how to automatically create a panorama using feature
% based image registration techniques.
%
% Copyright 2014 The MathWorks, Inc.

%% Overview
% Feature detection and matching are powerful techniques used in many
% computer vision applications such as image registration, tracking, and
% object detection. In this example, feature based techniques are used to
% automatically stitch together a set of images. The procedure for image
% stitching is an extension of feature based image registration. Instead of
% registering a single pair of images, multiple image pairs are
% successively registered relative to each other to form a panorama.

%% Step 1 - Load Images
% The image set used in this example contains pictures of a building. These
% were taken with an uncalibrated smart phone camera by sweeping the camera
% from left to right along the horizon, capturing all parts of the
% building.
%
% As seen below, the images are relatively unaffected by any lens
% distortion so camera calibration was not required. However, if lens
% distortion is present, the camera should be calibrated and the images
% undistorted prior to creating the panorama. You can use the
% |<matlab:doc('cameraCalibrator'); cameraCalibrator>| App to calibrate a camera if needed.

% Load images.
buildingDir = fullfile(toolboxdir('vision'), 'visiondata', 'building');
buildingScene = imageDatastore(buildingDir);

% Display images to be stitched
montage(buildingScene.Files)

%% Step 2 - Register Image Pairs 
% To create the panorama, start by registering successive image pairs using
% the following procedure:
%
% # Detect and match features between $I(n)$ and $I(n-1)$.
% # Estimate the geometric transformation, $T(n)$, that maps $I(n)$ to $I(n-1)$.
% # Compute the transformation that maps $I(n)$ into the panorama image as $T(1) * ... * T(n-1) * T(n)$.

% Read the first image from the image set.
I = readimage(buildingScene, 1);

% Initialize features for I(1)
grayImage = rgb2gray(I);
points = detectSURFFeatures(grayImage);
[features, points] = extractFeatures(grayImage, points);

% Initialize all the transforms to the identity matrix. Note that the
% projective transform is used here because the building images are fairly
% close to the camera. Had the scene been captured from a further distance,
% an affine transform would suffice.
numImages = numel(buildingScene.Files);
tforms(numImages) = projective2d(eye(3));

% Iterate over remaining image pairs
for n = 2:numImages
    
    % Store points and features for I(n-1).
    pointsPrevious = points;
    featuresPrevious = features;
        
    % Read I(n).
    I = readimage(buildingScene, n);
    
    % Detect and extract SURF features for I(n).
    grayImage = rgb2gray(I);    
    points = detectSURFFeatures(grayImage);    
    [features, points] = extractFeatures(grayImage, points);
  
    % Find correspondences between I(n) and I(n-1).
    indexPairs = matchFeatures(features, featuresPrevious, 'Unique', true);
       
    matchedPoints = points(indexPairs(:,1), :);
    matchedPointsPrev = pointsPrevious(indexPairs(:,2), :);        
    
    % Estimate the transformation between I(n) and I(n-1).
    tforms(n) = estimateGeometricTransform(matchedPoints, matchedPointsPrev,...
        'projective', 'Confidence', 99.9, 'MaxNumTrials', 2000);
    
    % Compute T(1) * ... * T(n-1) * T(n)
    tforms(n).T = tforms(n-1).T * tforms(n).T; 
end

%%
% At this point, all the transformations in |tforms| are relative to the
% first image. This was a convenient way to code the image registration
% procedure because it allowed sequential processing of all the images.
% However, using the first image as the start of the panorama does not
% produce the most aesthetically pleasing panorama because it tends to
% distort most of the images that form the panorama. A nicer panorama can
% be created by modifying the transformations such that the center of the
% scene is the least distorted. This is accomplished by inverting the
% transform for the center image and applying that transform to all the
% others.
%
% Start by using the |projective2d| |outputLimits| method to find the
% output limits for each transform. The output limits are then used to
% automatically find the image that is roughly in the center of the scene.

imageSize = size(I);  % all the images are the same size

% Compute the output limits  for each transform
for i = 1:numel(tforms)           
    [xlim(i,:), ylim(i,:)] = outputLimits(tforms(i), [1 imageSize(2)], [1 imageSize(1)]);    
end

%%
% Next, compute the average X limits for each transforms and find the image
% that is in the center. Only the X limits are used here because the scene
% is known to be horizontal. If another set of images are used, both the X
% and Y limits may need to be used to find the center image.

avgXLim = mean(xlim, 2);

[~, idx] = sort(avgXLim);

centerIdx = floor((numel(tforms)+1)/2);

centerImageIdx = idx(centerIdx);

%%
% Finally, apply the center image's inverse transform to all the others.

Tinv = invert(tforms(centerImageIdx));

for i = 1:numel(tforms)    
    tforms(i).T = Tinv.T * tforms(i).T;
end

%% Step 3 - Initialize the Panorama
% Now, create an initial, empty, panorama into which all the images are
% mapped. 
% 
% Use the |outputLimits| method to compute the minimum and maximum output
% limits over all transformations. These values are used to automatically
% compute the size of the panorama.

for i = 1:numel(tforms)           
    [xlim(i,:), ylim(i,:)] = outputLimits(tforms(i), [1 imageSize(2)], [1 imageSize(1)]);
end

% Find the minimum and maximum output limits 
xMin = min([1; xlim(:)]);
xMax = max([imageSize(2); xlim(:)]);

yMin = min([1; ylim(:)]);
yMax = max([imageSize(1); ylim(:)]);

% Width and height of panorama.
width  = round(xMax - xMin);
height = round(yMax - yMin);

% Initialize the "empty" panorama.
panorama = zeros([height width 3], 'like', I);

%% Step 4 - Create the Panorama
% Use |imwarp| to map images into the panorama and use
% |vision.AlphaBlender| to overlay the images together.

blender = vision.AlphaBlender('Operation', 'Binary mask', ...
    'MaskSource', 'Input port');  

% Create a 2-D spatial reference object defining the size of the panorama.
xLimits = [xMin xMax];
yLimits = [yMin yMax];
panoramaView = imref2d([height width], xLimits, yLimits);

% Create the panorama.
for i = 1:numImages
    
    I = readimage(buildingScene, i);   
   
    % Transform I into the panorama.
    warpedImage = imwarp(I, tforms(i), 'OutputView', panoramaView);
                  
    % Generate a binary mask.    
    mask = imwarp(true(size(I,1),size(I,2)), tforms(i), 'OutputView', panoramaView);
    
    % Overlay the warpedImage onto the panorama.
    panorama = step(blender, panorama, warpedImage, mask);
end

figure
imshow(panorama)

%% Conclusion
% This example showed you how to automatically create a panorama using
% feature based image registration techniques. Additional techniques can be
% incorporated into the example to improve the blending and alignment of
% the panorama images[1]. 

%% References
% [1] Matthew Brown and David G. Lowe. 2007. Automatic Panoramic Image
%     Stitching using Invariant Features. Int. J. Comput. Vision 74, 1
%     (August 2007), 59-73.

displayEndOfDemoMessage(mfilename)

##### SOURCE END #####
--></body></html>